{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "brave-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "# from torch.autograd import Variable\n",
    "# from perceiver_pytorch import Perceiver\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "from babi_joint import BabiDataset, pad_collate\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from glob import glob\n",
    "from perceiver_pytorch import PerceiverIObAbI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "macro-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PerceiverIObAbI(\n",
    "    num_tokens=179,\n",
    "    context_max_seq_len=70*13,\n",
    "    question_max_seq_len=13,\n",
    "    dim = 16,                    # dimension of sequence to be encoded\n",
    "    queries_dim = 179,            # dimension of decoder queries\n",
    "#     logits_dim = 50,            # dimension of final logits\n",
    "    depth = 3,                   # depth of net\n",
    "    num_latents = 13,           # number of latents, or induced set points, or centroids. different papers giving it different names\n",
    "    latent_dim = 16,            # latent dimension\n",
    "    cross_heads = 1,             # number of heads for cross attention. paper said 1\n",
    "    latent_heads = 8,            # number of heads for latent self attention, 8\n",
    "    cross_dim_head = 32,         # number of dimensions per cross attention head\n",
    "    latent_dim_head = 32,        # number of dimensions per latent self attention head\n",
    "    weight_tie_layers = True,   # whether to weight tie layers (optional, as indicated in the diagram)\n",
    "    self_per_cross_attn = 2,     # number of self attention blocks per cross attention\n",
    ")\n",
    "\n",
    "model_name = 'perceiverIO_bAbi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "interim-tomorrow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(babi_dataset) train 180000\n",
      "vocab_size 179\n",
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf657c510444eaf88cea6da1d1aa68b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/2:   0%|          | 0/1407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "effeefef\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "x.shape torch.Size([128, 910, 16])\n",
      "self.pe[:x.size(0)].shape torch.Size([128, 1, 16])\n",
      "x.shape torch.Size([128, 13, 16])\n",
      "self.pe[:x.size(0)].shape torch.Size([13, 1, 16])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (128) must match the size of tensor b (13) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-369c72644423>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0manswers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Fun/Python Projects/dissertation/perceiver-recurrence-experiments/perceiver_pytorch/perceiver_io.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, contexts, questions)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mquestions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0mquestions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestion_pe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0manswer_queries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manswer_query\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manswer_query\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manswer_query\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (?, 1, num_tokens)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Fun/Python Projects/dissertation/perceiver-recurrence-experiments/perceiver_pytorch/perceiver_io.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x.shape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'self.pe[:x.size(0)].shape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (128) must match the size of tensor b (13) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "max_epochs = 2\n",
    "\n",
    "babi_dataset = BabiDataset(ds_path='/home/gabriel/Documents/datasets/bAbi/en/qa{}_*', \n",
    "                           vocab_path='/home/gabriel/Documents/datasets/bAbi/en/babi{}_vocab.pkl')\n",
    "vocab_size = len(babi_dataset.QA.VOCAB)\n",
    "print('len(babi_dataset) train', len(babi_dataset))\n",
    "print('vocab_size', vocab_size)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "val_loss_min = float('-inf')\n",
    "\n",
    "writer = SummaryWriter()\n",
    "if not os.path.isdir(f'checkpoints/{model_name}'):\n",
    "    os.mkdir(f'checkpoints/{model_name}')\n",
    "now = datetime.now().strftime(\"%d_%m_%Y__%H_%M_%S\")\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    loss_sum = 0\n",
    "    loss_count = 0\n",
    "    model.train()\n",
    "\n",
    "    babi_dataset.set_mode('train')\n",
    "    train_loader = DataLoader(\n",
    "        babi_dataset, batch_size=batch_size, shuffle=True, collate_fn=pad_collate\n",
    "    )\n",
    "    \n",
    "    for batch_idx, data in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{max_epochs}\")):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        contexts, questions, answers = data\n",
    "        print('effeefef')\n",
    "        print(type(contexts), type(questions), type(answers))\n",
    "        contexts = contexts.long().to(device)\n",
    "        questions = questions.long().to(device)\n",
    "        answers = answers.to(device)\n",
    "        \n",
    "        logits = model(contexts, questions)\n",
    "        loss = criterion(logits, answers)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.data\n",
    "        writer.add_scalars(\"losses_step\", {\"train_loss\": loss.data}, epoch * len(train_loader) + batch_idx)\n",
    "        \n",
    "    model.eval()\n",
    "    \n",
    "    babi_dataset.set_mode('valid')\n",
    "    val_loader = DataLoader(\n",
    "        babi_dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(val_loader):\n",
    "        \n",
    "            contexts, questions, answers = data\n",
    "            contexts = contexts.long().to(device)\n",
    "            questions = questions.long().to(device)\n",
    "            answers = answers.to(device)\n",
    "        \n",
    "            logits = model(contexts, questions)\n",
    "            loss = criterion(logits, answers)\n",
    "            val_loss += loss.data\n",
    "\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    \n",
    "    writer.add_scalars(\"losses_step\", {\"val_loss\": val_loss}, (epoch + 1) * len(train_loader) - 1)\n",
    "    \n",
    "    writer.add_scalars(\"losses_epoch\", {\"train_loss\": train_loss}, epoch)\n",
    "    writer.add_scalars(\"losses_epoch\", {\"val_loss\": val_loss}, epoch)\n",
    "    \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch+1, \n",
    "        train_loss,\n",
    "        val_loss\n",
    "    ))\n",
    "    \n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'valid_loss_min': val_loss,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }\n",
    "    \n",
    "    torch.save(checkpoint, f'checkpoints/{model_name}/checkpoint_{now}.pt')\n",
    "    if val_loss <= val_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(val_loss_min,val_loss))\n",
    "        torch.save(checkpoint, f'checkpoints/{model_name}/best_checkpoint_{now}.pt')\n",
    "        val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")aset\n",
    "model.to(device)\n",
    "# checkpoint = torch.load(f'checkpoints/{model_name}/best_checkpoint.pt')\n",
    "# model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()\n",
    "m = nn.Softmax(dim=1)\n",
    "\n",
    "babi_dataset.set_mode('test')\n",
    "test_loader = DataLoader(\n",
    "    babi_dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate\n",
    ")\n",
    "\n",
    "y_pred_extended = []\n",
    "y_true_extended = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (X_batch, y_batch) in enumerate(tqdm(test_loader, desc=f\"Inference\")):\n",
    "        contexts, questions, answers = data\n",
    "        contexts = Variable(contexts.long().to(device))\n",
    "        questions = Variable(questions.long().to(device))\n",
    "        answers = Variable(answers.to(device))\n",
    "\n",
    "        logits = model(contexts, questions)\n",
    "        y_pred = m(logits)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        y_pred_extended.extend(y_pred)\n",
    "        y_true_extended.extend(answers.cpu())\n",
    "        \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    #else:\n",
    "        #print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "    \n",
    "    plt.figure(figsize=(25,25))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "accuracy = accuracy_score(y_pred_extended, y_true_extended)\n",
    "cr = classification_report(y_true_extended, y_pred_extended)\n",
    "print(accuracy)\n",
    "print(cr)\n",
    "cnf_matrix = confusion_matrix(y_true_extended, y_pred_extended)\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[str(i) for i in list(range(10))], title = ('Confusion Matrix'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
