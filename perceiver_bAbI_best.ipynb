{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "brave-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from perceiver_pytorch import Perceiver\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "from babi_joint import BabiDataset, pad_collate\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from glob import glob\n",
    "from perceiver_pytorch.perceiver_io_ponder import PerceiverIObAbInq, PonderLoss\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UT pondernet 1470003\n",
    "\n",
    "model = PerceiverIObAbInq(\n",
    "    num_tokens=179,\n",
    "    context_max_seq_len=71*13,\n",
    "#     question_max_seq_len=13,\n",
    "    dim = 32,                    # dimension of sequence to be encoded\n",
    "    queries_dim = 178,            # dimension of decoder queries\n",
    "    logits_dim = 178,            # dimension of final logits\n",
    "    depth = 20,                   # depth of net\n",
    "    num_latents = 32,           # number of latents, or induced set points, or centroids. different papers giving it different names\n",
    "    latent_dim = 64,            # latent dimension\n",
    "    cross_heads = 1,             # number of heads for cross attention. paper said 1\n",
    "    latent_heads = 8,            # number of heads for latent self attention, 8\n",
    "    cross_dim_head = 64,         # number of dimensions per cross attention head\n",
    "    latent_dim_head = 64,        # number of dimensions per latent self attention head\n",
    "    weight_tie_layers = True,   # whether to weight tie layers (optional, as indicated in the diagram)\n",
    "    self_per_cross_attn = 1,     # number of self attention blocks per cross attention\n",
    "    learn_latents=True\n",
    ")\n",
    "\n",
    "model_name = 'perceiverIO_bAbi_nq_deep'\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "max_epochs = 150\n",
    "\n",
    "babi_dataset = BabiDataset(ds_path='/home/gabriel/Documents/datasets/bAbi/en/qa{}_*', \n",
    "                           vocab_path='/home/gabriel/Documents/datasets/bAbi/en/babi{}_vocab.pkl')\n",
    "vocab_size = len(babi_dataset.QA.VOCAB)\n",
    "print('len(babi_dataset) train', len(babi_dataset))\n",
    "print('vocab_size', vocab_size)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "model.to(device)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "depth = 20\n",
    "criterion = PonderLoss(nn.CrossEntropyLoss(reduction='none'), 1/10, depth, 0.01).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "val_loss_min = float('inf')\n",
    "\n",
    "writer = SummaryWriter()\n",
    "if not os.path.isdir(f'checkpoints/{model_name}'):\n",
    "    os.mkdir(f'checkpoints/{model_name}')\n",
    "now = datetime.now().strftime(\"%d_%m_%Y__%H_%M_%S\")\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    loss_sum = 0\n",
    "    loss_count = 0\n",
    "    model.train()\n",
    "    babi_dataset.set_mode('train')\n",
    "    train_loader = DataLoader(\n",
    "        babi_dataset, batch_size=batch_size, shuffle=True, collate_fn=pad_collate\n",
    "    )\n",
    "    \n",
    "    for batch_idx, data in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{max_epochs}\")):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        contexts, answers, tasks = data\n",
    "        contexts = contexts.long().to(device)\n",
    "#         questions = questions.long().to(device)\n",
    "        answers = answers.to(device)\n",
    "        \n",
    "        p, y_hat, p_sampled, y_hat_sampled = model(contexts)\n",
    "        loss = criterion(p, y_hat, answers)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        writer.add_scalars(\"losses_step\", {\"train_loss\": loss.item() / contexts.size(0)}, epoch * len(train_loader) + batch_idx)\n",
    "    \n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    writer.add_scalars(\"losses_epoch\", {\"train_loss\": train_loss}, epoch)\n",
    "    train_loader_len = len(train_loader)\n",
    "    \n",
    "    model.eval()\n",
    "    babi_dataset.set_mode('valid')\n",
    "    val_loader = DataLoader(\n",
    "        babi_dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(val_loader):\n",
    "        \n",
    "            contexts, answers, tasks = data\n",
    "            contexts = contexts.long().to(device)\n",
    "#             questions = questions.long().to(device)\n",
    "            answers = answers.to(device)\n",
    "        \n",
    "            p, y_hat, p_sampled, y_hat_sampled = model(contexts)\n",
    "            loss = criterion(p, y_hat, answers)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    writer.add_scalars(\"losses_step\", {\"val_loss\": val_loss}, (epoch + 1) * train_loader_len - 1)    \n",
    "    writer.add_scalars(\"losses_epoch\", {\"val_loss\": val_loss}, epoch)\n",
    "    \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch+1, \n",
    "        train_loss,\n",
    "        val_loss\n",
    "    ))\n",
    "    \n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'valid_loss_min': val_loss,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }\n",
    "    \n",
    "    torch.save(checkpoint, f'checkpoints/{model_name}/checkpoint_{now}.pt')\n",
    "    if val_loss <= val_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(val_loss_min,val_loss))\n",
    "        torch.save(checkpoint, f'checkpoints/{model_name}/best_checkpoint_{now}.pt')\n",
    "        val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "checkpoint_name = f'checkpoints/{model_name}/best_checkpoint_{now}.pt'\n",
    "checkpoint = torch.load(checkpoint_name)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()\n",
    "m = nn.Softmax(dim=1)\n",
    "\n",
    "babi_dataset.set_mode('test')\n",
    "test_loader = DataLoader(\n",
    "    babi_dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate\n",
    ")\n",
    "\n",
    "y_pred_extended = []\n",
    "y_true_extended = []\n",
    "y_pred_task = [[] for _ in range(20)]\n",
    "y_true_task = [[] for _ in range(20)]\n",
    "\n",
    "start = time.time()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(tqdm(test_loader, desc=f\"Inference\")):\n",
    "        contexts, answers, tasks = data\n",
    "        contexts = contexts.long().to(device)\n",
    "#         questions = questions.long().to(device)\n",
    "        answers = answers.to(device)\n",
    "\n",
    "        p, y_hat, p_sampled, y_hat_sampled = model(contexts)\n",
    "        # We consider a task successfully passed if â‰¥ 95% accuracy is obtained.\n",
    "        y_pred = m(y_hat_sampled.cpu())\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        y_pred = [babi_dataset.QA.IVOCAB[int(i)] for i in y_pred]\n",
    "        y_true = [babi_dataset.QA.IVOCAB[int(i)] for i in answers.cpu()]\n",
    "        y_pred_extended.extend(y_pred)\n",
    "        y_true_extended.extend(y_true)\n",
    "        for i in range(len(y_pred)):\n",
    "            y_pred_task[int(tasks[i]) - 1].append(y_pred[i])\n",
    "            y_true_task[int(tasks[i]) - 1].append(y_true[i])\n",
    "end = time.time()\n",
    "\n",
    "        \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    #else:\n",
    "        #print('Confusion matrix, without normalization')p.shape\n",
    "\n",
    "    #print(cm)\n",
    "    \n",
    "    plt.figure(figsize=(25,25))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "accuracy = accuracy_score(y_pred_extended, y_true_extended)\n",
    "cr = classification_report(y_true_extended, y_pred_extended)\n",
    "print(accuracy)\n",
    "print(cr)\n",
    "task_acc = []\n",
    "passed_tasks = []\n",
    "for i in range(20):\n",
    "    task_acc.append(accuracy_score(y_pred_task[i], y_true_task[i]))\n",
    "    passed_tasks.append(1 if task_acc[i] >= 0.95 else 0)\n",
    "print(task_acc)\n",
    "print('passed_tasks:', passed_tasks)\n",
    "print('no. passed_tasks:', sum(passed_tasks))\n",
    "labels = list(set(y_true_extended).intersection(set(y_true_extended)))\n",
    "cnf_matrix = confusion_matrix(y_true_extended, y_pred_extended, labels)\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(cnf_matrix, classes=labels, title = ('Confusion Matrix'))\n",
    "plt.show()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from thop import profile\n",
    "# from thop import clever_format\n",
    "\n",
    "# macs, params = profile(model, inputs=(\n",
    "#                         torch.randint(1, size=(1, 910)).type(torch.LongTensor).to(device), \n",
    "#                         torch.randint(1, size=(1, 13)).type(torch.LongTensor).to(device)))  # , \n",
    "# #                         custom_ops={YourModule: count_your_model})\n",
    "\n",
    "# macs, params = clever_format([macs, params], \"%.3f\")\n",
    "# print(macs, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.layers.append(model.layers[1])\n",
    "print(len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-convertible",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(babi_dataset.QA.IVOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "recent-israeli",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41aecea1036d49c7bc2f786c0ef4a128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 5:\n",
      "bill travelled to the garden <EOS> bill moved to the kitchen <EOS> mary moved to the garden <EOS> jeff went back to the garden <EOS> jeff went to the hallway <EOS> bill went to the bathroom <EOS> mary went to the hallway <EOS> mary travelled to the bedroom <EOS> jeff went back to the bedroom <EOS> bill went to the hallway <EOS> mary went to the bathroom <EOS> jeff went to the bathroom <EOS> mary journeyed to the garden <EOS> fred went back to the hallway <EOS> mary moved to the bedroom <EOS> bill travelled to the office <EOS> fred travelled to the office <EOS> mary journeyed to the kitchen <EOS> fred went to the hallway <EOS> mary travelled to the bedroom <EOS> mary went back to the garden <EOS> fred journeyed to the bedroom <EOS> jeff journeyed to the office <EOS> bill went back to the bedroom <EOS> fred travelled to the kitchen <EOS> fred moved to the hallway <EOS> fred journeyed to the office <EOS> fred moved to the bathroom <EOS> mary travelled to the office <EOS> jeff journeyed to the bedroom <EOS> fred moved to the bedroom <EOS> mary went to the bathroom <EOS> fred travelled to the bathroom <EOS> jeff journeyed to the kitchen <EOS> mary journeyed to the office <EOS> fred moved to the bedroom <EOS> mary moved to the bathroom <EOS> mary went back to the bedroom <EOS> mary went back to the hallway <EOS> mary went back to the office <EOS> bill travelled to the hallway <EOS> bill journeyed to the kitchen <EOS> jeff travelled to the office <EOS> fred went to the garden <EOS> bill went to the bedroom <EOS> fred went to the office <EOS> bill went to the kitchen <EOS> jeff went to the garden <EOS> fred journeyed to the bathroom <EOS> fred journeyed to the kitchen <EOS> fred went back to the bathroom <EOS> mary went back to the hallway <EOS> fred went to the garden <EOS> mary grabbed the apple there <EOS> mary discarded the apple <EOS> bill travelled to the garden <EOS> mary travelled to the office <EOS> jeff journeyed to the bathroom <EOS> fred journeyed to the bedroom <EOS> bill moved to the kitchen <EOS> mary travelled to the bedroom <EOS> mary moved to the garden <EOS> bill went to the garden <EOS> mary went back to the hallway <EOS> bill moved to the bedroom <EOS> mary moved to the bathroom <EOS> fred travelled to the kitchen <EOS> mary travelled to the garden <EOS> bill went to the hallway <EOS> bill picked up the football there <EOS> fred moved to the office <EOS> bill dropped the football <EOS> jeff travelled to the kitchen <EOS> bill went to the garden <EOS> mary travelled to the hallway <EOS> mary journeyed to the bathroom <EOS> mary journeyed to the office <EOS> fred travelled to the bathroom <EOS> fred journeyed to the kitchen <EOS> fred journeyed to the bedroom <EOS> jeff travelled to the garden <EOS> bill went to the bedroom <EOS> mary went to the garden <EOS> bill moved to the kitchen <EOS> fred went to the office <EOS> mary travelled to the hallway <EOS> jeff travelled to the kitchen <EOS> fred travelled to the garden <EOS> fred went to the bedroom <EOS> mary took the football there <EOS> bill moved to the bathroom <EOS> mary went back to the bathroom <EOS> mary passed the football to bill <EOS> bill journeyed to the hallway <EOS> fred journeyed to the hallway <EOS> jeff moved to the hallway <EOS> jeff grabbed the milk there <EOS> bill gave the football to fred <EOS> jeff travelled to the office <EOS> fred gave the football to bill <EOS> bill gave the football to fred <EOS> fred grabbed the apple there <EOS> who received the football <EOS> (632 words)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ff214b6ad5f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#         print(f'Task {int(tasks[b])}:')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m#                 print(babi_dataset.QA.IVOCAB[int(w)], end=\" \")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "babi_dataset = BabiDataset(ds_path='/home/gabriel/Documents/datasets/bAbi/en/qa{}_*', \n",
    "                           vocab_path='/home/gabriel/Documents/datasets/bAbi/en/babi{}_vocab.pkl')\n",
    "vocab_size = len(babi_dataset.QA.VOCAB)\n",
    "babi_dataset.set_mode('train')\n",
    "train_loader = DataLoader(\n",
    "    babi_dataset, batch_size=batch_size, shuffle=True, collate_fn=pad_collate\n",
    ")\n",
    "max_context = 0\n",
    "for batch_idx, data in enumerate(tqdm(train_loader)):  \n",
    "    contexts, answers, tasks = data\n",
    "#     print(contexts.shape, answers.shape)\n",
    "    for b in range(contexts.shape[0]):\n",
    "#         print(f'Task {int(tasks[b])}:')\n",
    "        for i, w in enumerate(contexts[b]):\n",
    "            if w != 0:\n",
    "#                 print(babi_dataset.QA.IVOCAB[int(w)], end=\" \")\n",
    "                pass\n",
    "            else:\n",
    "#                 print(f'({i} words)')\n",
    "                if i > max_context:\n",
    "                    max_context = i\n",
    "                    if i > 600:\n",
    "                        print(f'Task {int(tasks[b])}:')\n",
    "                        for i, w in enumerate(contexts[b]):\n",
    "                            if w != 0:\n",
    "                                print(babi_dataset.QA.IVOCAB[int(w)], end=\" \")\n",
    "                            else:\n",
    "                                print(f'({i} words)')\n",
    "                                break\n",
    "                break\n",
    "#         print('\\n')\n",
    "#         print(babi_dataset.QA.IVOCAB[int(answers[b])])\n",
    "#         print('\\n')\n",
    "#     break\n",
    "print(max_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spiritual-beast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<EOS>', 2: 'mary', 3: 'moved', 4: 'to', 5: 'the', 6: 'bathroom', 7: 'john', 8: 'went', 9: 'hallway', 10: 'where', 11: 'is', 12: 'daniel', 13: 'back', 14: 'sandra', 15: 'garden', 16: 'office', 17: 'journeyed', 18: 'travelled', 19: 'bedroom', 20: 'kitchen', 21: 'got', 22: 'football', 23: 'there', 24: 'dropped', 25: 'milk', 26: 'took', 27: 'picked', 28: 'up', 29: 'apple', 30: 'left', 31: 'grabbed', 32: 'discarded', 33: 'put', 34: 'down', 35: 'was', 36: 'before', 37: 'north', 38: 'of', 39: 'south', 40: 'what', 41: 'west', 42: 'east', 43: 'bill', 44: 'gave', 45: 'fred', 46: 'did', 47: 'give', 48: 'handed', 49: 'jeff', 50: 'who', 51: 'received', 52: 'passed', 53: 'in', 54: 'no', 55: 'yes', 56: 'how', 57: 'many', 58: 'objects', 59: 'carrying', 60: 'one', 61: 'none', 62: 'two', 63: 'three', 64: 'nothing', 65: 'football,apple', 66: 'milk,apple', 67: 'apple,football', 68: 'football,milk', 69: 'milk,football', 70: 'milk,football,apple', 71: 'apple,milk', 72: 'apple,milk,football', 73: 'apple,football,milk', 74: 'football,milk,apple', 75: 'milk,apple,football', 76: 'football,apple,milk', 77: 'longer', 78: 'not', 79: 'either', 80: 'school', 81: 'or', 82: 'park', 83: 'cinema', 84: 'maybe', 85: 'julie', 86: 'after', 87: 'that', 88: 'she', 89: 'afterwards', 90: 'he', 91: 'following', 92: 'then', 93: 'and', 94: 'they', 95: 'yesterday', 96: 'this', 97: 'morning', 98: 'afternoon', 99: 'evening', 100: 'mice', 101: 'are', 102: 'afraid', 103: 'wolves', 104: 'gertrude', 105: 'a', 106: 'mouse', 107: 'cats', 108: 'sheep', 109: 'winona', 110: 'emily', 111: 'jessica', 112: 'wolf', 113: 'cat', 114: 'lily', 115: 'frog', 116: 'bernhard', 117: 'green', 118: 'brian', 119: 'lion', 120: 'white', 121: 'julius', 122: 'swan', 123: 'greg', 124: 'color', 125: 'rhino', 126: 'gray', 127: 'yellow', 128: 'triangle', 129: 'above', 130: 'pink', 131: 'rectangle', 132: 'blue', 133: 'square', 134: 'right', 135: 'below', 136: 'red', 137: 'sphere', 138: 'box', 139: 'chocolates', 140: 'fits', 141: 'inside', 142: 'chest', 143: 'bigger', 144: 'than', 145: 'suitcase', 146: 'container', 147: 'does', 148: 'fit', 149: 'chocolate', 150: 'do', 151: 'you', 152: 'go', 153: 'from', 154: 's,e', 155: 'n,w', 156: 'n,n', 157: 's,w', 158: 'e,s', 159: 's,s', 160: 'e,n', 161: 'w,w', 162: 'e,e', 163: 'n,e', 164: 'w,s', 165: 'w,n', 166: 'sumit', 167: 'tired', 168: 'will', 169: 'why', 170: 'pajamas', 171: 'get', 172: 'yann', 173: 'bored', 174: 'jason', 175: 'thirsty', 176: 'antoine', 177: 'hungry'}\n"
     ]
    }
   ],
   "source": [
    " print(babi_dataset.QA.IVOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-cable",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
